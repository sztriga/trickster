Metadata-Version: 2.4
Name: trickster
Version: 0.2.0
Summary: Hungarian card game framework with AlphaZero MCTS training and React UI.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: fastapi
Requires-Dist: uvicorn
Requires-Dist: numpy
Provides-Extra: dev
Requires-Dist: pytest==8.3.4; extra == "dev"

## Trickster — card-based AI game (engine + train + GUI)

This is a **minimal**, non-Streamlit project where you can:

- **Train** a simple AI via self-play
- **Play** against the trained AI in a small local GUI

### Game rules (this project)

- Deck (Schnapsen / Hungarian "snapszer" direction): **Hungarian suits** (Hearts, Bells, Leaves, Acorns) × ranks
  **J, Q, K, 10, A** (20 cards)
- Card points: **J=2, Q=3, K=4, 10=10, A=11**
- At the start, each player gets **5 cards**
- The remaining cards form a **face-down draw pile**
- Each trick:
  - The **leader** plays (“calls”) a card
  - The **responder** must play the **same color** if possible
    - If they have any **higher** number in that color, they must respond with a **higher** one (they may choose which)
    - If they only have **lower** cards of that color, they must play one of those
  - If they **cannot follow color**, they may play any card
  - Winner:
    - If responder followed color and played **higher**, responder wins the round
    - Otherwise leader wins the round
- After the trick, **both players draw back up to 5 cards** (if possible):
  - **Winner draws first**, then the other player
- Each trick winner takes the **sum of the two cards' points**
- The game ends after **10 tricks** (the full 20-card deck is used)
- The player with the most points wins

### “Random baseline” vs “untrained model”

- **Random baseline** (used in Evaluate → “Progress vs baseline”): a player that picks a **uniform random legal card** every time. This is the clean, comparable baseline for **both** Linear and MLP.
- **Untrained Linear model**: all weights start at 0, so every action scores 0.5 and the agent breaks ties randomly ⇒ it behaves essentially like the random baseline.
- **Untrained MLP model**: weights are randomly initialized, so it is a **fixed random policy** (not uniform random). It can have accidental preferences even before training, which is why the GUI baseline uses the explicit uniform-random opponent instead of “checkpoint 0 MLP”.

### Run from project root (no PYTHONPATH)

Install once (editable), then you can run without `PYTHONPATH`:

```bash
python3 -m pip install -e .
```

### Run (GUI: train + play)

```bash
python3 -m trickster.gui
```

### Run (headless training)

```bash
python3 -m trickster.cli --episodes 2000 --seed 0
```

This trains the selected model and writes rolling slots under its own folder:

- `models/<model_id>/latest.pkl`
- `models/<model_id>/prev.pkl`

### Checkpoints ("pixels") + learning curve

In the GUI Train tab you can set **Pixels (checkpoints)**. This saves models into:

- `models/<model_id>/checkpoints/ckpt_XXXXXXXXX.pkl`

Then in the Evaluate tab you can run a **checkpoint curve** that evaluates
checkpoint \(i\) vs \(i+1\) to measure incremental improvement.

